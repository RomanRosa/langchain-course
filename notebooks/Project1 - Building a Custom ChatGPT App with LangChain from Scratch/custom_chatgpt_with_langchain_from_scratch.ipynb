{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custome ChatGPT App With LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain.memory import FileChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= FileChatMessageHistory('chat_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Chat Memory using ConversationBufferMemory\n",
    "memory= ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speed of light in a vacuum is approximately 299,792,458 meters per second, which is often rounded to 300,000 kilometers per second. This is an important constant in physics and is denoted by the symbol \"c.\"\n",
      "--------------------------------------------------\n",
      "The speed of light in water is slower than in a vacuum. It is approximately 225,000 kilometers per second. The exact speed may vary slightly depending on the temperature and composition of the water, but it is significantly slower compared to its speed in a vacuum.\n",
      "--------------------------------------------------\n",
      "On average, light from the Sun takes approximately 8 minutes and 20 seconds to travel to Earth. This time is known as the \"light travel time\" or \"time of flight.\" It is due to the vast distance between the Sun and the Earth, which is about 93 million miles (150 million kilometers). Therefore, when we observe the Sun, we are seeing it as it appeared about 8 minutes and 20 seconds ago.\n",
      "--------------------------------------------------\n",
      "Transformers are electrical devices that efficiently transfer electrical energy between two or more circuits using electromagnetic induction. They consist of two or more coils, known as windings, that are wrapped around a magnetic core. When an alternating current (AC) passes through the primary winding, it creates a fluctuating magnetic field in the core, which induces a voltage in the secondary winding. By manipulating the number of turns in the windings, transformers can either step up (increase) or step down (decrease) the voltage and current levels, making them essential for electricity distribution and power transmission systems.\n",
      "--------------------------------------------------\n",
      "In the field of artificial intelligence (AI), transformers refer to a type of deep learning model that is highly effective for various tasks involving natural language processing (NLP). Transformers are based on a self-attention mechanism that allows them to capture the relationships between different words in a sentence or sequence of words. This enables transformers to understand complex dependencies and contextual information, leading to improved performance in tasks such as language translation, text generation, sentiment analysis, and more. Transformers have revolutionized NLP and are widely used in state-of-the-art AI models such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer).\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "llm= ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "prompt= ChatPromptTemplate(\n",
    "    input_variables=['content'],\n",
    "    messages=[\n",
    "        SystemMessage(content='You are a chatbot having a conversation with a human!.'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'), # Where The Memory Will Be Stored\n",
    "        HumanMessagePromptTemplate.from_template('{content}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain= LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content= input('Your Prompt: ')\n",
    "    if content in ['quit','exit','bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response= chain.run({'content':content})\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
