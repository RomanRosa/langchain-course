{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custome ChatGPT App With LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I assist you today?\n",
      "--------------------------------------------------\n",
      "The softmax function is a mathematical function commonly used in machine learning and statistics. It maps a vector of real numbers to a vector of probabilities. \n",
      "\n",
      "Given an input vector x = [x1, x2, ..., xn], the softmax function produces an output vector y = [y1, y2, ..., yn] where each element yi is calculated as follows:\n",
      "\n",
      "yi = exp(xi) / (exp(x1) + exp(x2) + ... + exp(xn))\n",
      "\n",
      "In other words, the softmax function exponentiates each element in the input vector and then normalizes them by dividing by the sum of all exponentiated elements. This normalization ensures that the resulting output vector y represents a probability distribution, as the values are non-negative and sum up to 1.\n",
      "\n",
      "The softmax function is commonly used in multiclass classification problems, where the goal is to assign an input sample to one of multiple classes. The output probabilities generated by softmax can be interpreted as the probability of the input sample belonging to each class. The class with the highest probability is often chosen as the predicted class.\n",
      "--------------------------------------------------\n",
      "The softmax function is a mathematical function commonly used in machine learning and deep learning algorithms. It takes an input vector of real numbers and normalizes it into a probability distribution over multiple classes. The output of the softmax function is always a set of values between 0 and 1, which sum up to 1.\n",
      "\n",
      "The formula for the softmax function is as follows:\n",
      "\n",
      "softmax(x_i) = exp(x_i) / sum(exp(x_j))\n",
      "\n",
      "Here, x_i represents the individual elements of the input vector x, while exp() denotes the exponential function. The softmax function calculates the probability of each element in the input vector being selected by normalizing the exponentiated values of the input vector with the sum of all exponentiated values in the same vector.\n",
      "\n",
      "By applying the softmax function to a vector, we obtain a probability distribution over the different classes represented by the elements of the vector. This makes it especially useful in multi-class classification tasks, where we want to assign a probability to each class.\n",
      "\n",
      "The softmax function is often used as the output activation function in neural networks, particularly in the final layer for multi-class classification problems. It allows us to interpret the output of the neural network as probabilities and make predictions based on these probabilities.\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "llm= ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "prompt= ChatPromptTemplate(\n",
    "    input_variables=['content'],\n",
    "    messages=[\n",
    "        SystemMessage(content='You are a chatbot having a conversation with a human!.'),\n",
    "        HumanMessagePromptTemplate.from_template('{content}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain= LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content= input('Your Prompt: ')\n",
    "    if content in ['quit','exit','bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response= chain.run({'content':content})\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
